{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp5zht0CqSe/nE8CM4oitD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JadeEmm/ai-image-captioning-app/blob/main/AI_Image_Captioning_App_(Public).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM-awIoVP8pt"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: Welcome & Instructions (Markdown)\n",
        "# ============================================================================\n",
        "\n",
        "\"\"\"\n",
        "# AI Image Captioning App - Try It Now!\n",
        "\n",
        "Welcome! This notebook lets you run a professional AI image captioning app directly in your browser.\n",
        "\n",
        "## How to use this notebook:\n",
        "\n",
        "1. **Click \"Copy to Drive\"** (top-left) to get your own copy\n",
        "2. **Run all cells** below in order (Ctrl+Enter or click the play buttons)\n",
        "3. **Wait for the app to load** (takes 1-2 minutes first time)\n",
        "4. **Click the public link** that appears to access your app\n",
        "5. **Upload images and get AI captions!**\n",
        "\n",
        "##What you'll get:\n",
        "- A working AI app with public link to share\n",
        "- State-of-the-art image captioning (Salesforce BLIP model)\n",
        "- No setup required - everything runs in the cloud\n",
        "- Free to use and share with friends!\n",
        "\n",
        "## Real world use cases solutions like this are great for:\n",
        "- Content creators needing captions\n",
        "- Learning about AI and computer vision\n",
        "- Accessibility (generating alt text)\n",
        "\n",
        "---\n",
        "\n",
        "**Ready? Let's build your AI app!**\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 2: Setup & Installation\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Setting up your AI Image Captioning App...\")\n",
        "print(\"Installing required packages...\")\n",
        "\n",
        "# Install packages (with progress bar)\n",
        "!pip install transformers torch torchvision gradio Pillow --quiet --progress-bar off\n",
        "\n",
        "print(\"All packages installed successfully!\")\n",
        "print(\"Loading libraries...\")\n",
        "\n",
        "# Import everything we need\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Libraries loaded!\")\n",
        "\n",
        "# Check what device we're using\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "device_name = \"GPU \" if device == 0 else \"CPU üíª\"\n",
        "print(f\"Your app will use: {device_name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Setup complete! Ready to load AI model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 3: Load AI Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Loading AI model...\")\n",
        "print(\"Downloading Salesforce BLIP model (this takes a moment)...\")\n",
        "\n",
        "# Load the AI model using Hugging Face pipeline\n",
        "try:\n",
        "    caption_pipeline = pipeline(\n",
        "        \"image-to-text\",\n",
        "        model=\"Salesforce/blip-image-captioning-base\",\n",
        "        device=device\n",
        "    )\n",
        "    print(\"AI model loaded successfully!\")\n",
        "    print(\"Ready to understand and describe images!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Trying CPU fallback...\")\n",
        "\n",
        "    # Fallback to CPU\n",
        "    caption_pipeline = pipeline(\n",
        "        \"image-to-text\",\n",
        "        model=\"Salesforce/blip-image-captioning-base\",\n",
        "        device=-1\n",
        "    )\n",
        "    print(\"Model loaded on CPU!\")\n",
        "\n",
        "print(\"\\nAI is ready to caption your images!\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 4: Caption Generation Function\n",
        "# ============================================================================\n",
        "\n",
        "def generate_caption(image):\n",
        "    \"\"\"\n",
        "    Generate caption for uploaded image\n",
        "    This is the main function that powers your app!\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return \"‚ùå Please upload an image first!\"\n",
        "\n",
        "    try:\n",
        "        print(\"AI is analysing your image...\")\n",
        "\n",
        "        # Make sure image is in the right format\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Generate caption using AI\n",
        "        result = caption_pipeline(image)\n",
        "\n",
        "        # Extract the caption\n",
        "        if result and len(result) > 0:\n",
        "            caption = result[0]['generated_text']\n",
        "            print(f\"Caption generated: '{caption}'\")\n",
        "            return f\"{caption}\"\n",
        "        else:\n",
        "            return \"Could not generate caption for this image.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "# Test the function\n",
        "print(\"Testing the AI with a simple image...\")\n",
        "\n",
        "# Create a test image (blue square)\n",
        "import numpy as np\n",
        "test_img = Image.fromarray(np.full((100, 100, 3), [100, 150, 200], dtype=np.uint8))\n",
        "test_result = generate_caption(test_img)\n",
        "print(f\"Test result: {test_result}\")\n",
        "\n",
        "if \"Error\" not in test_result:\n",
        "    print(\"‚úÖ AI is working perfectly!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è There might be an issue - but let's continue...\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 5: Create the App Interface\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Creating your app interface...\")\n",
        "\n",
        "# Create the Gradio interface\n",
        "app = gr.Interface(\n",
        "    fn=generate_caption,\n",
        "    inputs=[\n",
        "        gr.Image(\n",
        "            label=\"Upload Any Image\",\n",
        "            type=\"pil\",\n",
        "            sources=[\"upload\", \"webcam\"],\n",
        "            height=350\n",
        "        )\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"AI Generated Caption\",\n",
        "            placeholder=\"Upload an image and watch AI describe it here!\",\n",
        "            lines=3,\n",
        "            max_lines=5\n",
        "        )\n",
        "    ],\n",
        "\n",
        "    title=\"AI Image Captioning App\",\n",
        "\n",
        "    description=\"\"\"\n",
        "    ## Upload any image and get an instant AI description!\n",
        "\n",
        "    **What this does:**\n",
        "    - Upload a photo from your computer or take one with your webcam\n",
        "    - Advanced AI analyses the image content\n",
        "    - Get a natural language description in seconds\n",
        "\n",
        "    **Real world use cases solutions like this are great for:**\n",
        "    - Content creators needing captions\n",
        "    - Accessibility (alt text generation)\n",
        "    - Learning how AI \"sees\" images\n",
        "\n",
        "    **Powered by:** Salesforce BLIP - a state-of-the-art vision AI model\n",
        "    \"\"\",\n",
        "\n",
        "    article=\"\"\"\n",
        "    ### How it works:\n",
        "\n",
        "    This app uses **BLIP** (Bootstrapping Language-Image Pre-training), one of the most advanced\n",
        "    AI models for understanding images. It was trained on millions of image-text pairs to learn\n",
        "    how to describe visual content in natural language.\n",
        "\n",
        "    ### Educational Value:\n",
        "\n",
        "    This demonstrates the incredible progress in **Computer Vision** and **Natural Language Processing**.\n",
        "    The AI doesn't just recognize objects - it understands relationships, contexts, and can describe\n",
        "    complex scenes in human-like language.\n",
        "\n",
        "    ### Technical Details:\n",
        "    - **Model:** Salesforce BLIP (14M parameters)\n",
        "    - **Framework:** Hugging Face Transformers\n",
        "    - **Interface:** Gradio\n",
        "    - **Runtime:** Google Colab (free)\n",
        "\n",
        "    ---\n",
        "\n",
        "    **Enjoy exploring AI image captioning!**\n",
        "\n",
        "    *Built using Python, Transformers, and Gradio*\n",
        "    \"\"\",\n",
        "\n",
        "    theme=gr.themes.Soft(),\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Interface created successfully!\")\n",
        "print(\"Your app is ready to launch!\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 6: Launch the App\n",
        "# ============================================================================\n",
        "\n",
        "print(\"LAUNCHING YOUR AI IMAGE CAPTIONING APP!\")\n",
        "print(\"Creating public link... (this takes a moment)\")\n",
        "print(\"Your app will be accessible to anyone with the link!\")\n",
        "\n",
        "# Close any existing apps\n",
        "gr.close_all()\n",
        "\n",
        "# Launch with public sharing\n",
        "app.launch(\n",
        "    share=True,      # Creates public link anyone can access\n",
        "    debug=False,     # Clean interface\n",
        "    show_error=True, # Show helpful error messages\n",
        "    quiet=False      # Show the public link\n",
        ")\n",
        "\n",
        "print(\"SUCCESS! Your AI app is now running!\")\n",
        "print(\"\\nIMPORTANT: Use the public link above to access your app\")\n",
        "print(\"üîó Share this link with friends - they can use your app too\")\n",
        "print(\"Try it with photos, screenshots, drawings - anything!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONGRATULATIONS!\")\n",
        "print(\"You've successfully built and deployed an AI application!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 7: Bonus Features & Tips (Markdown)\n",
        "# ============================================================================\n",
        "\n",
        "\"\"\"\n",
        "## Tips for Best Results:\n",
        "\n",
        "### Image Quality:\n",
        "- **Clear, well-lit photos** work best\n",
        "- **Single main subject** gets more accurate descriptions\n",
        "- **Common objects/scenes** are described most accurately\n",
        "- **High resolution** isn't necessary - AI works with any size\n",
        "\n",
        "### Experiments to Try:\n",
        "- Upload artwork and see how AI interprets it\n",
        "- Try historical photos vs modern ones\n",
        "- Test with drawings or sketches\n",
        "- Compare AI descriptions with your own\n",
        "\n",
        "### Sharing Your App:\n",
        "- The public link works for 72 hours\n",
        "- Anyone can use it without signing up\n",
        "- No usage limits - caption as many images as you want!\n",
        "\n",
        "### Customisation Ideas:\n",
        "- Try different AI models (change the model name in Cell 3)\n",
        "- Add multiple caption generation\n",
        "- Include confidence scores\n",
        "- Build batch processing for multiple images\n",
        "\n",
        "---\n",
        "\n",
        "## What You've Learned:\n",
        "\n",
        "‚úÖ How to use Hugging Face Transformers\n",
        "‚úÖ Computer vision and AI model deployment\n",
        "‚úÖ Creating web interfaces with Gradio\n",
        "‚úÖ Running AI models in the cloud\n",
        "‚úÖ Building shareable AI applications\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Want the source code? Check out the GitHub repository for the full project!:"
      ],
      "metadata": {
        "id": "eCrIJFfPSrY_"
      }
    }
  ]
}
