# AI Image Captioning App

An intelligent image captioning application that generates descriptive text for any uploaded image using Salesforce's BLIP (Bootstrapping Language-Image Pre-training) model via Hugging Face API.

![App Demo](https://img.shields.io/badge/Demo-Live-brightgreen) ![Python](https://img.shields.io/badge/Python-3.7+-blue) ![Gradio](https://img.shields.io/badge/Gradio-Latest-orange)

## Features

- **Easy Image Upload**: Drag & drop or click to upload any image
- **Webcam Support**: Take photos directly from your camera
- **AI-Powered Captions**: Uses state-of-the-art BLIP model for accurate descriptions
- **Instant Results**: Get captions in seconds
- **Clean Interface**: User-friendly web interface built with Gradio
- **Free to Use**: Runs on Google Colab for free

## Quick Start

### Option 1: Run on Google Colab (Recommended)

1. **Open in Colab**: [![Open In Colab](https://colab.research.google.com/github/JadeEmm/ai-image-captioning-app/blob/main/AI_Image_Captioning_App_Google_Colab_Notebook(Public).ipynb)

2. **Set up your API key**:
   - Go to [Hugging Face](https://huggingface.co/) and create a free account
   - Generate an API token: Settings ‚Üí Access Tokens ‚Üí New Token
   - In Colab, click the key icon (üîë) on the left sidebar
   - Add a new secret: Name = `HF_TOKEN`, Value = your API token

3. **Run the app**:
   - Run all cells in the notebook
   - Click the public link that appears
   - Start captioning images!

### Option 2: Run Locally

```bash
# Clone the repository
git clone https://github.com/JadeEmm/image-captioning-app.git
cd image-captioning-app

# Install dependencies
pip install -r requirements.txt

# Set your Hugging Face API key as environment variable
export HF_TOKEN="your_hugging_face_api_key_here"

# Run the app
python app.py
```

## üìÅ Project Structure

```
image-captioning-app/
‚îÇ
‚îú‚îÄ‚îÄ AI_Image_Captioning_App_Google_Colab_Notebook(Public).ipynb    # Main Colab notebook
‚îú‚îÄ‚îÄ app.py                        # Standalone Python app
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ README.md                     # This file
‚îî‚îÄ‚îÄ examples/                     # Example images for testing
    ‚îú‚îÄ‚îÄ sample_1.jpg
    ‚îú‚îÄ‚îÄ sample_2.jpg
    ‚îî‚îÄ‚îÄ sample_3.jpg
```

## üõ†Ô∏è How It Works

1. **Image Processing**: Uploaded images are converted to base64 format
2. **API Call**: Image data is sent to Hugging Face's BLIP model endpoint
3. **Caption Generation**: The AI model analyzes the image and generates a descriptive caption
4. **Display Results**: The caption is displayed in the user interface

## üß† About the AI Model

This app uses **Salesforce's BLIP** (Bootstrapping Language-Image Pre-training) model:
- **Model Size**: 14M parameters
- **Training**: Pre-trained on millions of image-text pairs
- **Capabilities**: Understands objects, scenes, actions, and relationships in images
- **Accuracy**: High-quality captions for diverse image types

## Customization

Want to modify the app? Here are some ideas:

- **Change Model**: Replace the API endpoint to use different captioning models
- **Add Features**: Include confidence scores, multiple caption options, or image classification
- **Styling**: Customize the Gradio theme and layout
- **Batch Processing**: Add support for multiple image uploads

## Demo & Social Media
- **LinkedIn Post**: [Link to your LinkedIn demo]
- **Video Demo**: [Link to your demo video]

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **Salesforce** for the BLIP model
- **Hugging Face** for the API and model hosting
- **Gradio** for the amazing interface framework
- **Google Colab** for free GPU/CPU resources

## Contact

- **GitHub**: [@JadeEmm](https://github.com/JadeEmm)
- **LinkedIn**: [Your LinkedIn Profile](https://linkedin.com/in/jade-emmanuel)

---

‚≠ê If you found this project helpful, please give it a star on GitHub!

## üè∑Ô∏è Tags

`artificial-intelligence` `computer-vision` `image-captioning` `machine-learning` `deep-learning` `gradio` `huggingface` `python` `blip` `ai-app`
